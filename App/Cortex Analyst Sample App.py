# =============================================================================
# ã‚¢ãƒ—ãƒªå: Cortex Analyst ã‚¢ãƒ—ãƒªï¼ˆæ—¥æœ¬èªž UIï¼‰
# =============================================================================
# æ¦‚è¦:
# - Snowflake Cortex Analyst ã¨é€£æºã—ã€è‡ªç„¶è¨€èªžï¼ˆæ—¥æœ¬èªžï¼‰ã§ãƒ‡ãƒ¼ã‚¿ã«è³ªå•ãƒ»åˆ†æžã§ãã‚‹
#   Streamlit ã‚¢ãƒ—ãƒªã§ã™ã€‚
# - ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ â†’ ã‚¹ã‚­ãƒ¼ãƒž â†’ ã‚»ãƒžãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ“ãƒ¥ãƒ¼ï¼ˆFQNï¼‰ã‚’é †ã«é¸æŠžã—ã€Cortex Analyst
#   API ã«å¯¾è©±å±¥æ­´ã¨é¸æŠžã—ãŸã‚»ãƒžãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ“ãƒ¥ãƒ¼ã‚’é€ä¿¡ã—ã¦å›žç­”ï¼ˆãƒ†ã‚­ã‚¹ãƒˆ/SQL/å¯è¦–åŒ–ï¼‰ã‚’å¾—ã¾ã™ã€‚
#
# ä¸»ãªæ©Ÿèƒ½:
# - ãƒãƒ£ãƒƒãƒˆä½“é¨“
#   - åˆå›ž: ã‚»ãƒžãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ“ãƒ¥ãƒ¼é¸æŠžæ¸ˆã¿ãªã‚‰è‡ªå‹•ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé€ä¿¡
#   - å…¥åŠ›: st.chat_input ã‹ã‚‰æ—¥æœ¬èªžã§è³ªå•
#   - å¿œç­”: Cortex Analyst API ã‹ã‚‰ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸/SQL/è­¦å‘Šã‚’è¡¨ç¤º
# - SQL ã®è¡¨ç¤ºã¨å®Ÿè¡Œ
#   - ç”Ÿæˆ SQL ã‚’é–‹é–‰è¡¨ç¤º
#   - Verified Query Repository æƒ…å ±ã®ãƒãƒƒãƒ—ã‚ªãƒ¼ãƒãƒ¼è¡¨ç¤º
#   - Snowpark çµŒç”±ã§ SQL å®Ÿè¡Œ â†’ ãƒ‡ãƒ¼ã‚¿ã‚¿ãƒ–/ã‚°ãƒ©ãƒ•ã‚¿ãƒ–ï¼ˆæŠ˜ã‚Œç·š/æ£’ï¼‰ã§å¯è¦–åŒ–
# - ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯é€ä¿¡
#   - ç”Ÿæˆ SQL ã«å¯¾ã—ã€ŒðŸ‘/ðŸ‘Žã€ã¨ä»»æ„ã‚³ãƒ¡ãƒ³ãƒˆã‚’ API ã¸é€ä¿¡
# - ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
#   - API ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹/ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®æ•´å½¢è¡¨ç¤º
#   - ã‚¹ãƒˆãƒªãƒ¼ãƒ ãƒªãƒƒãƒˆã®ãƒˆãƒ¼ã‚¹ãƒˆé€šçŸ¥
#
# å‰ææ¡ä»¶:
# - Snowflake ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒæœ‰åŠ¹ï¼ˆSnowflake Notebooks / Streamlit å®Ÿè¡Œç’°å¢ƒï¼‰
# - å¯¾è±¡ã‚»ãƒžãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ“ãƒ¥ãƒ¼ã«ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ãªãƒ­ãƒ¼ãƒ«æ¨©é™
# - Cortex Analyst API åˆ©ç”¨ãŒè¨±å¯ã•ã‚Œã¦ã„ã‚‹ã“ã¨
# - å‚ç…§ã™ã‚‹ã‚»ãƒžãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ“ãƒ¥ãƒ¼ãŒäº‹å‰ã«ä½œæˆæ¸ˆã¿
#
# å‚è€ƒ:
# - Snowflake Quickstartï¼ˆã‚»ãƒžãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ“ãƒ¥ãƒ¼ï¼‰
#   https://quickstarts.snowflake.com/guide/snowflake-semantic-view/index.html?index=..%2F..index#6
#
# è¨­å®š/å®šæ•°:
# - API_ENDPOINT / FEEDBACK_API_ENDPOINT / API_TIMEOUT ã‚’ã‚³ãƒ¼ãƒ‰å†…å®šæ•°ã§ç®¡ç†
#
#
# ä½œæˆè€…: Sakuragi (Snowflake)
# æœ€çµ‚æ›´æ–°æ—¥: 2025-10-05
# =============================================================================
import json
import time
from datetime import datetime
from typing import Dict, List, Optional, Tuple, Union

import _snowflake
import pandas as pd
import streamlit as st
from snowflake.snowpark.context import get_active_session
from snowflake.snowpark.exceptions import SnowparkSQLException

API_ENDPOINT = "/api/v2/cortex/analyst/message"
FEEDBACK_API_ENDPOINT = "/api/v2/cortex/analyst/feedback"
API_TIMEOUT = 50000

session = get_active_session()


def main():
    if "messages" not in st.session_state:
        reset_session_state()
    show_header_and_sidebar()

    # ã‚»ãƒžãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ“ãƒ¥ãƒ¼ãŒé¸ã°ã‚Œã¦ã„ã‚‹å ´åˆã®ã¿è‡ªå‹•ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    if len(st.session_state.messages) == 0 and st.session_state.get("selected_semantic_view_fqn"):
        process_user_input("ã©ã‚“ãªåˆ†æžãŒã§ãã¾ã™ã‹ï¼Ÿæ—¥æœ¬èªžã§æ•™ãˆã¦ãã ã•ã„ã€‚")

    display_conversation()
    handle_user_inputs()
    handle_error_notifications()
    #display_warnings()


def reset_session_state():
    st.session_state.messages = []
    st.session_state.active_suggestion = None
    st.session_state.warnings = []
    st.session_state.form_submitted = {}


@st.cache_data(show_spinner=False)
def list_databases() -> List[str]:
    candidates: List[str] = []
    # 1) æ¨™æº–: SHOW DATABASES
    try:
        df = session.sql("SHOW DATABASES").to_pandas()
        df.columns = [str(c).lower() for c in df.columns]
        if "name" in df.columns:
            candidates.extend([str(x) for x in df["name"].tolist() if x])
    except Exception:
        pass
    # 2) ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼: ACCOUNT_USAGEï¼ˆæ¨©é™ã‚ã‚‹å ´åˆã®ã¿ï¼‰
    try:
        df2 = session.sql(
            "SELECT DATABASE_NAME FROM SNOWFLAKE.ACCOUNT_USAGE.DATABASES "
            "WHERE DELETED IS NULL ORDER BY DATABASE_NAME"
        ).to_pandas()
        df2.columns = [str(c).lower() for c in df2.columns]
        if "database_name" in df2.columns:
            candidates.extend([str(x) for x in df2["database_name"].tolist() if x])
    except Exception:
        pass
    return sorted({c for c in candidates})


def _quote_ident(name: str) -> str:
    s = str(name).replace('"', '""')
    return f'"{s}"'


@st.cache_data(show_spinner=False)
def list_schemas(database: str) -> List[str]:
    if not database:
        return []
    try:
        df = session.sql(
            f"SELECT SCHEMA_NAME FROM {_quote_ident(database)}.INFORMATION_SCHEMA.SCHEMATA ORDER BY SCHEMA_NAME"
        ).to_pandas()
        df.columns = [str(c).lower() for c in df.columns]
        col = "schema_name" if "schema_name" in df.columns else None
        if col is None:
            return []
        return [str(x) for x in df[col].tolist()]
    except Exception:
        return []


@st.cache_data(show_spinner=False)
def list_semantic_views(database: str, schema: str) -> List[str]:
    if not database or not schema:
        return []
    try:
        # ã‚¯ã‚ªãƒ¼ãƒˆä»˜ã SHOWï¼ˆå°æ–‡å­—/ç‰¹æ®Šæ–‡å­—å¯¾å¿œï¼‰
        q = f"SHOW SEMANTIC VIEWS IN SCHEMA {_quote_ident(database)}.{_quote_ident(schema)}"
        df = session.sql(q).to_pandas()

        # åˆ—åã‚’æ­£è¦åŒ–ï¼ˆå‰å¾Œç©ºç™½/äºŒé‡å¼•ç”¨ç¬¦ã‚’é™¤åŽ»ã—ã¦å°æ–‡å­—åŒ–ï¼‰
        norm_map = {orig: str(orig).strip().strip('"').lower() for orig in df.columns}
        # 'name' ã«å¯¾å¿œã™ã‚‹å…ƒã®åˆ—åã‚’ç‰¹å®šï¼ˆname, "name", NAME ãªã©ã‚’å¸åŽï¼‰
        names_col = next((orig for orig, norm in norm_map.items() if norm == "name"), None)
        if not names_col:
            return []

        names = [str(x).strip() for x in df[names_col].dropna().tolist() if str(x).strip()]
        return [f"{database}.{schema}.{n}" for n in names]
    except Exception:
        return []


def _on_database_change():
    try:
        list_schemas.clear()
        list_semantic_views.clear()
    except Exception:
        pass
    st.session_state.selected_schema = None
    st.session_state.selected_semantic_view_fqn = None
    reset_session_state()


def _on_schema_change():
    try:
        list_semantic_views.clear()
    except Exception:
        pass
    st.session_state.selected_semantic_view_fqn = None
    reset_session_state()


def _on_view_change():
    reset_session_state()


def _clear_metadata_cache():
    try:
        list_databases.clear()
        list_schemas.clear()
        list_semantic_views.clear()
    except Exception:
        pass


def _get_current_context_defaults() -> Tuple[Optional[str], Optional[str], Optional[str], Optional[str]]:
    try:
        df = session.sql(
            "SELECT CURRENT_DATABASE() AS DB, CURRENT_SCHEMA() AS SCHEMA, CURRENT_WAREHOUSE() AS WH, CURRENT_ROLE() AS ROLE"
        ).to_pandas()
        db = str(df["DB"].iloc[0]) if not pd.isna(df["DB"].iloc[0]) else None
        sc = str(df["SCHEMA"].iloc[0]) if not pd.isna(df["SCHEMA"].iloc[0]) else None
        wh = str(df["WH"].iloc[0]) if not pd.isna(df["WH"].iloc[0]) else None
        role = str(df["ROLE"].iloc[0]) if not pd.isna(df["ROLE"].iloc[0]) else None
        return db, sc, wh, role
    except Exception:
        return None, None, None, None


def show_header_and_sidebar():
    st.title("Cortex Analyst")
    st.markdown("Cortex Analyst ã¸ã‚ˆã†ã“ãã€‚ä¸‹ã®å…¥åŠ›æ¬„ã«è³ªå•ã‚’æ—¥æœ¬èªžã§å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

    with st.sidebar:
        db_default, schema_default, wh, role = _get_current_context_defaults()

        st.caption("æŽ¥ç¶šæƒ…å ±")
        ctx_cols = st.columns(2)
        ctx_cols[0].text_input("ç¾åœ¨ã®ãƒ­ãƒ¼ãƒ«", value=role or "", disabled=True)
        ctx_cols[1].text_input("ç¾åœ¨ã®ã‚¦ã‚§ã‚¢ãƒã‚¦ã‚¹", value=wh or "", disabled=True)

        st.divider()
        st.caption("ã‚»ãƒžãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ“ãƒ¥ãƒ¼ã®é¸æŠž")

        # Database
        dbs = list_databases()
        if "selected_database" not in st.session_state or st.session_state.selected_database not in dbs:
            st.session_state.selected_database = db_default if db_default in dbs else (dbs[0] if dbs else None)

        st.selectbox(
            "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹",
            dbs,
            key="selected_database",
            on_change=_on_database_change,
        )

        # Schema
        schemas = list_schemas(st.session_state.selected_database) if st.session_state.selected_database else []
        if "selected_schema" not in st.session_state or st.session_state.selected_schema not in schemas:
            st.session_state.selected_schema = schema_default if schema_default in schemas else (schemas[0] if schemas else None)

        st.selectbox(
            "ã‚¹ã‚­ãƒ¼ãƒž",
            schemas,
            key="selected_schema",
            on_change=_on_schema_change,
            disabled=not bool(schemas),
        )

        # Semantic View
        views = (
            list_semantic_views(st.session_state.selected_database, st.session_state.selected_schema)
            if st.session_state.selected_database and st.session_state.selected_schema
            else []
        )
        if (
            "selected_semantic_view_fqn" not in st.session_state
            or st.session_state.selected_semantic_view_fqn not in views
        ):
            st.session_state.selected_semantic_view_fqn = views[0] if views else None

        if views:
            st.selectbox(
                "ã‚»ãƒžãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ“ãƒ¥ãƒ¼",
                views,
                format_func=lambda s: s.split(".")[-1] if s else s,
                key="selected_semantic_view_fqn",
                on_change=_on_view_change,
            )
        else:
            st.info("é¸æŠžä¸­ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹/ã‚¹ã‚­ãƒ¼ãƒžã«ã‚»ãƒžãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ“ãƒ¥ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

        st.caption("é¸æŠžä¸­ã® FQN")
        st.code(st.session_state.get("selected_semantic_view_fqn") or "(æœªé¸æŠž)", language="text")

        st.divider()
        btn_cols = st.columns(2)
        if btn_cols[0].button("ðŸ”„ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°", use_container_width=True):
            _clear_metadata_cache()
            st.rerun()
        if btn_cols[1].button("ä¼šè©±å±¥æ­´ã‚’ã‚¯ãƒªã‚¢", use_container_width=True):
            reset_session_state()
            st.rerun()


def handle_user_inputs():
    if not st.session_state.get("selected_semantic_view_fqn"):
        st.info("å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ»ã‚¹ã‚­ãƒ¼ãƒžãƒ»ã‚»ãƒžãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ“ãƒ¥ãƒ¼ã‚’é¸æŠžã—ã¦ãã ã•ã„ã€‚")
    user_input = st.chat_input("ã”è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    if user_input:
        if not st.session_state.get("selected_semantic_view_fqn"):
            st.toast("ã‚»ãƒžãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ“ãƒ¥ãƒ¼ã‚’é¸æŠžã—ã¦ãã ã•ã„ã€‚", icon="âš ï¸")
            return
        process_user_input(user_input)
    elif st.session_state.active_suggestion is not None:
        suggestion = st.session_state.active_suggestion
        st.session_state.active_suggestion = None
        process_user_input(suggestion)


def handle_error_notifications():
    if st.session_state.get("fire_API_error_notify"):
        st.toast("API ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸï¼", icon="ðŸš¨")
        st.session_state["fire_API_error_notify"] = False


def process_user_input(prompt: str):
    st.session_state.warnings = []

    new_user_message = {
        "role": "user",
        "content": [{"type": "text", "text": prompt}],
    }
    st.session_state.messages.append(new_user_message)
    with st.chat_message("user"):
        user_msg_index = len(st.session_state.messages) - 1
        display_message(new_user_message["content"], user_msg_index)

    with st.chat_message("analyst"):
        with st.spinner("Cortex Analyst ã®å¿œç­”ã‚’å¾…æ©Ÿä¸­..."):
            time.sleep(1)
            response, error_msg = get_analyst_response(st.session_state.messages)
            if error_msg is None:
                analyst_message = {
                    "role": "analyst",
                    "content": response["message"]["content"],
                    "request_id": response["request_id"],
                }
            else:
                analyst_message = {
                    "role": "analyst",
                    "content": [{"type": "text", "text": error_msg}],
                    "request_id": response["request_id"],
                }
                st.session_state["fire_API_error_notify"] = True

            if "warnings" in response:
                st.session_state.warnings = response["warnings"]

            st.session_state.messages.append(analyst_message)
            st.rerun()


def display_warnings():
    warnings = st.session_state.warnings
    for warning in warnings:
        st.warning(warning["message"], icon="âš ï¸")


def get_analyst_response(messages: List[Dict]) -> Tuple[Dict, Optional[str]]:
    request_body = {
        "messages": messages,
        "semantic_view": st.session_state.get("selected_semantic_view_fqn"),
    }
    resp = _snowflake.send_snow_api_request(
        "POST",
        API_ENDPOINT,
        {},
        {},
        request_body,
        None,
        API_TIMEOUT,
    )

    parsed_content = json.loads(resp["content"])

    if resp["status"] < 400:
        return parsed_content, None
    else:
        error_msg = f"""
ðŸš¨ Cortex Analyst API ã‚¨ãƒ©ãƒ¼ ðŸš¨

* å¿œç­”ã‚³ãƒ¼ãƒ‰: `{resp['status']}`
* ãƒªã‚¯ã‚¨ã‚¹ãƒˆID: `{parsed_content.get('request_id', '(unknown)')}`
* ã‚¨ãƒ©ãƒ¼ã‚³ãƒ¼ãƒ‰: `{parsed_content.get('error_code', '(unknown)')}`

ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸:
        """
        return parsed_content, error_msg


def display_conversation():
    for idx, message in enumerate(st.session_state.messages):
        role = message["role"]
        content = message["content"]
        with st.chat_message(role):
            if role == "analyst":
                display_message(content, idx, message.get("request_id"))
            else:
                display_message(content, idx)


def display_message(
    content: List[Dict[str, Union[str, Dict]]],
    message_index: int,
    request_id: Union[str, None] = None,
):
    for item in content:
        if item["type"] == "text":
            st.markdown(item["text"])
        elif item["type"] == "suggestions":
            for suggestion_index, suggestion in enumerate(item["suggestions"]):
                if st.button(
                    suggestion, key=f"suggestion_{message_index}_{suggestion_index}"
                ):
                    st.session_state.active_suggestion = suggestion
        elif item["type"] == "sql":
            display_sql_query(
                item["statement"], message_index, item.get("confidence"), request_id
            )
        else:
            pass


@st.cache_data(show_spinner=False)
def get_query_exec_result(query: str) -> Tuple[Optional[pd.DataFrame], Optional[str]]:
    global session
    try:
        df = session.sql(query).to_pandas()
        return df, None
    except SnowparkSQLException as e:
        return None, str(e)


def display_sql_confidence(confidence: dict):
    if confidence is None:
        return
    verified_query_used = confidence.get("verified_query_used")
    with st.popover(
        "æ¤œè¨¼æ¸ˆã¿ã‚¯ã‚¨ãƒªã®åˆ©ç”¨çŠ¶æ³",
        help="Verified Query Repository ã«ã‚ã‚‹æ¤œè¨¼æ¸ˆã¿ã‚¯ã‚¨ãƒªã‚’ç”¨ã„ã¦ SQL ãŒç”Ÿæˆã•ã‚ŒãŸã‹ã®æƒ…å ±ã§ã™ï¼ˆè©³ç´°ã¯ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å‚ç…§ï¼‰ã€‚",
    ):
        with st.container():
            if verified_query_used is None:
                st.text("ã“ã®å›žç­”ã®ç”Ÿæˆã« Verified Query ã¯ä½¿ç”¨ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
                return
            st.text(f"åç§°: {verified_query_used.get('name')}")
            st.text(f"è³ªå•: {verified_query_used.get('question')}")
            st.text(f"æ¤œè¨¼è€…: {verified_query_used.get('verified_by')}")
            st.text(f"æ¤œè¨¼æ—¥æ™‚: {datetime.fromtimestamp(verified_query_used.get('verified_at'))}")
            st.text("SQL ã‚¯ã‚¨ãƒª:")
            st.code(verified_query_used.get("sql", ""), language="sql", wrap_lines=True)


def display_sql_query(
    sql: str, message_index: int, confidence: dict, request_id: Union[str, None] = None
):
    with st.expander("ç”Ÿæˆã•ã‚ŒãŸ SQL", expanded=False):
        st.code(sql, language="sql")
        display_sql_confidence(confidence)

    with st.expander("çµæžœ", expanded=True):
        with st.spinner("SQL ã‚’å®Ÿè¡Œã—ã¦ã„ã¾ã™..."):
            df, err_msg = get_query_exec_result(sql)
            if df is None:
                st.error(f"ç”Ÿæˆã•ã‚ŒãŸ SQL ã‚’å®Ÿè¡Œã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ã‚¨ãƒ©ãƒ¼: {err_msg}")
            elif df.empty:
                st.write("ãƒ‡ãƒ¼ã‚¿ã¯è¿”ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
            else:
                data_tab, chart_tab = st.tabs(["ãƒ‡ãƒ¼ã‚¿ ðŸ“„", "ã‚°ãƒ©ãƒ• ðŸ“‰"])
                with data_tab:
                    st.dataframe(df, use_container_width=True)

                with chart_tab:
                    display_charts_tab(df, message_index)
    if request_id:
        display_feedback_section(request_id)


def display_charts_tab(df: pd.DataFrame, message_index: int) -> None:
    if len(df.columns) >= 2:
        all_cols_set = set(df.columns)
        col1, col2 = st.columns(2)
        x_col = col1.selectbox("X è»¸", all_cols_set, key=f"x_col_select_{message_index}")
        y_col = col2.selectbox("Y è»¸", all_cols_set.difference({x_col}), key=f"y_col_select_{message_index}")
        chart_type = st.selectbox("ã‚°ãƒ©ãƒ•ç¨®é¡žã‚’é¸æŠž", options=["æŠ˜ã‚Œç·šã‚°ãƒ©ãƒ• ðŸ“ˆ", "æ£’ã‚°ãƒ©ãƒ• ðŸ“Š"], key=f"chart_type_{message_index}")
        if chart_type == "æŠ˜ã‚Œç·šã‚°ãƒ©ãƒ• ðŸ“ˆ":
            st.line_chart(df.set_index(x_col)[y_col])
        elif chart_type == "æ£’ã‚°ãƒ©ãƒ• ðŸ“Š":
            st.bar_chart(df.set_index(x_col)[y_col])
    else:
        st.write("ã‚°ãƒ©ãƒ•ã«ã¯ 2 åˆ—ä»¥ä¸Šã®åˆ—ãŒå¿…è¦ã§ã™ã€‚")


def display_feedback_section(request_id: str):
    with st.popover("ðŸ“ ã‚¯ã‚¨ãƒªã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯"):
        if request_id not in st.session_state.form_submitted:
            with st.form(f"feedback_form_{request_id}", clear_on_submit=True):
                positive = st.radio("ç”Ÿæˆã•ã‚ŒãŸ SQL ã®è©•ä¾¡", options=["ðŸ‘", "ðŸ‘Ž"], horizontal=True)
                positive = positive == "ðŸ‘"
                submit_disabled = (
                    request_id in st.session_state.form_submitted
                    and st.session_state.form_submitted[request_id]
                )
                feedback_message = st.text_input("ä»»æ„ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯")
                submitted = st.form_submit_button("é€ä¿¡", disabled=submit_disabled)
                if submitted:
                    err_msg = submit_feedback(request_id, positive, feedback_message)
                    st.session_state.form_submitted[request_id] = {"error": err_msg}
                    st.session_state.popover_open = False
                    st.rerun()
        elif request_id in st.session_state.form_submitted and st.session_state.form_submitted[request_id]["error"] is None:
            st.success("ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’é€ä¿¡ã—ã¾ã—ãŸã€‚", icon="âœ…")
        else:
            st.error(st.session_state.form_submitted[request_id]["error"])


def submit_feedback(request_id: str, positive: bool, feedback_message: str) -> Optional[str]:
    request_body = {
        "request_id": request_id,
        "positive": positive,
        "feedback_message": feedback_message,
    }
    resp = _snowflake.send_snow_api_request(
        "POST",
        FEEDBACK_API_ENDPOINT,
        {},
        {},
        request_body,
        None,
        API_TIMEOUT,
    )
    if resp["status"] == 200:
        return None

    parsed_content = json.loads(resp["content"])
    err_msg = f"""
        ðŸš¨ Cortex Analyst API ã‚¨ãƒ©ãƒ¼ ðŸš¨
        
        * å¿œç­”ã‚³ãƒ¼ãƒ‰: `{resp['status']}`
        * ãƒªã‚¯ã‚¨ã‚¹ãƒˆID: `{parsed_content.get('request_id', '(unknown)')}`
        * ã‚¨ãƒ©ãƒ¼ã‚³ãƒ¼ãƒ‰: `{parsed_content.get('error_code', '(unknown)')}`
        
        ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸:
        ```
        {parsed_content.get('message', '')}
        ```
        """
    return err_msg


if __name__ == "__main__":
    main()